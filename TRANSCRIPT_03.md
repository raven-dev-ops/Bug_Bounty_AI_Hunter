
Transcript


Search in video
0:00
Good afternoon, Defcon. You guys sober?
0:06
Close enough. Our next speaker is a living legend. He
0:12
has been at Defcon for 30 years. He has spoken at 27. I'm going to need you to
0:18
make a lot of noise for Richard Thee. [Applause]
0:27
Thank you. Thank you very very much for showing up
0:33
and creating a space in which I can do this one more time. Um the start of any speech is where you
0:41
uh have the task of uh taking anxiety and uh adding oxygen to it and that's
0:47
what creates excitement and that's exactly what is the challenge
0:52
uh coming at us. I forgot that we had those noises from
0:58
the side. Um, okay. I'm going to do my best to ignore them and I hope you can
1:03
do the same. Uh, thinking like a hacker in the age of AI requires
1:09
us to act like we know exactly how hackers think and we have some idea. But
1:15
what I want to do is not give you a to-do list of things to take back to an office or ways to work with Claude. I
1:20
want to give you an approach to what is coming and what is happening because it is um every bit as big probably a lot
1:27
bigger than what happened when I noticed the internet arriving uh and began prognosticating about its
1:33
transformational capacity and what it was going to do to society. The accelerating evolution of technology
1:40
particularly AI really has taken us to an inflection point. We are now immersed
1:46
in what I think we can only call a meta system, an independent, constantly
1:51
shifting, opaque structure of algorithms, sensors, networks, and automated reasoning processes that touch
1:59
and will touch every aspect of our lives. The meta system is an emergent property. It's a product of billions of
2:06
interactions among machines and people, and it is shaping reality, our fundamental notions of reality, faster
2:13
than we can understand it. So whether it is thinking or simulating thinking doesn't matter. We have to
2:21
think differently and we have to think like hackers. Claude himself told me that it doesn't
2:29
know if it's thinking or simulating thinking and it asked the question can a
2:34
human do any better with that question than I can.
2:40
So adopting a hacker mindset lets us live and work in a system that is fully
2:47
redesigning its pausing for a minute because there's supposed to be a clock here. It's not on
2:58
uh adopting a hacker mindset allows us to live and work in a system that's redesigning itself with our creative
3:04
input. So, it's a system we don't fully understand and we do not entirely control it. And it helps to recognize
3:10
that as a result of this dynamic, we are redesigning ourselves and neither fully
3:16
understand nor completely control our behavior and thinking either. We are an ad hoc episode in the evolution of
3:24
intelligence. The old tools of analysis, cause and effect, linear thinking, fixed
3:31
categories are breaking down and the speed, scale, and complexity of the meta system defy them. So we have to live and
3:39
work and think in a way that empowers us humans in this symbiotic relationship.
3:45
In other words, we need to think like hackers. Yes, there are lots of exaggerated
3:51
projections of where we are going, but remember that Roy said we tend to overestimate the effect of a technology
3:58
in the short run and underestimate it in the long run. I think that's what's
4:03
happening here too. Uh we also defend ourselves against fear of the unknown by
4:09
ridiculing and poo pooing things that are actually happening as well as things
4:14
that might happen. And I want to warn against that. The uses of AI as the
4:21
expanding user base explores its potential, every transaction adding to
4:26
the gestalt that I call the metasphere are impossible to foresee in depth and
4:33
detail because the choices made by millions of users alter the users and
4:38
the AI moment to moment. So remember this adage that came from Marshall
4:44
McLuhan long ago. There is absolutely no inevitability as long as there is a
4:50
willingness to contemplate what is happening. It is impossible for humans
4:55
to visualize the results of exponential growth. So we usually do that through
5:02
science fiction. Science fiction is how a leftbrain society
5:07
dreams of its future. But over time the gap between vision and reality have
5:12
narrowed considerably. When Da Vinci suggested flying machines in 1480, we
5:17
had to wait over 400 years to get one. When Jules Vern wrote From the Earth to
5:23
the Moon in 1869, we had to wait only a 100red years until we were on the moon.
5:29
When Eldest Huxley wrote Brave New World in the 1930s, only a few decades later,
5:35
we were doing genetic engineering and conditioning our population. When William Gibson wrote Neurommancer in
5:42
1984, it was only 10 years till cyberspace was on everybody's tongue and everywhere in
5:49
our lives. The future arrives now thanks to these exponential changes across a horizontal
5:56
bandwidth not vertical as a result of interacting multimodal domains and
6:02
cross-disciplinary domains creating new high ad hoc categories and disciplines
6:08
on the fly. Many of the current disciplines now named did not exist only
6:14
10 or 20 years ago and experts in them cannot keep up with all the materials
6:21
published in their own areas of expertise. Hackers deal with this challenge.
6:28
Hackers deal with this challenge and ambiguity the way they work with six
6:34
screens open at a time. I have long thought that ADHD u was a feature not a bug and u it is
6:44
part of the power we have but nevertheless as smart as most of the people I should say all of the people uh
6:51
most just saw one I wasn't sure um as smart as all of the people in this
6:58
room are we still are assimilated and taken into our paradigms and our ways of
7:03
thinking we we just really can't help it. And uh it looks like this. A a guy
7:10
uh did an experiment with rats and memory. He had uh four four tunnels
7:18
and he put cheese at the end of the second tunnel and he put the rat in the
7:23
maze and the rat tried sniffing all the tunnels, went down the second tunnel, finally found the cheese. He did that
7:29
over and over and over again. And the rat just started going to tunnel two, tunnel two, tunnel two because he knew
7:35
where the cheese was. Um, and then the scientist, being human, being uh kind of
7:41
nasty, moved the cheese and the rat came to tunnel 2, went down. It came back
7:47
out, sniffed, came back down, came out, did it over and over again. And the
7:53
scientist taking notes had his hypothesis. Do you know the difference between that rat and a human being?
8:00
Eventually the rat will stop the and and so
8:08
uh that's true of all of us. We get habituated and then we don't think
8:13
outside of the way we have become accustomed to think and we apply that thinking to problems facing us now as if
8:20
they were the problem problems of just yesterday. So as we learn to engage with
8:27
AIS productively, I believe we will get
8:32
Thank you. addicted to the rush that we get. Um a
8:38
wonderful book called co-intelligence uh opens with an introduction in which the guy says if you don't have three
8:44
sleepless nights after engaging with an AI, you're not paying attention. uh you're excited and as I said Fritz
8:52
Pearl said excitement is uh anxiety plus oxygen but the anxiety can cause you to
8:58
be very uneasy and he had three sleepless nights thinking about what it really meant. I hope I have time at the
9:05
end to share just a little bit of what Claude told me when I prepared this talk. It took several weeks to get it
9:12
the way I wanted. Um, and then only then did I ask Claude, "Here's my topic. What
9:18
do you suggest? Any ideas?" That's all I asked. Claude gave me six brilliant
9:24
categories which I'll share at the end if I have time. And I took every category as you do and iterated and sent
9:30
it back into Claude. And now I have 20 to 25 pages of how hacking and hackers
9:36
thinking can apply in the world of AI and prompt engineering. Much of which I never would have understood before. I
9:43
took several weeks to write my talk. Claude took several seconds to output.
9:48
When it's something that you care about deeply, like I did about that topic, about the speech, it has to blow your
9:55
mind. So remember that insanity like wisdom is contextual.
10:03
uh when JCR Licklider in the 1950s told a group of intelligent scientists
10:09
that computers were going to be connected to one another in the future and talk to each other. They stood at
10:15
the back of the room going shovel shovel shovel. How much BS does he expect us to
10:20
believe? Um the context in which we live and move
10:26
defines what makes sense to us. And often when new things are evolving as
10:32
they are evolving rapidly now as as Robert Galvin of Motorola said um if you
10:39
go into a room for a meeting at Motorola he said and we have a problem and everybody agrees on the solution it it
10:46
was always wrong. It was always wrong because they brought the thinking of the paradigm in which they were captured
10:53
into the room and now it requires movement into a new way of understanding. And I'm going to give you
10:59
examples of how we have to think in this new way. Above all, you have to build in
11:06
an openness to heresy. You have to build in an openness to heresy because George
11:12
Bernard Shaw pointed out all great truth begins as blasphemy.
11:19
So even the truths you believe most deeply that you don't know you believe them are the ones that have to be
11:25
examined. And that's going to require a leap into a kind of metaconsciousness that I'm going to illuminate in terms of
11:31
how it evolves and how you can cooperate with your need to do that. I will have
11:36
some practical suggestions. So the AI revolution is asking because
11:42
of its unprecedented rate of adoption, its accelerated development, its widespread application to every
11:48
imaginable human enterprise. It is asking us not to dismiss predictions of
11:54
what is coming because they are going to fall far short in the long run. So
12:00
thinking differently sounds great. It's easy to talk about but actually thinking difficult differently is really hard.
12:08
Yet the future is not going to be what it used to be even yesterday. So really thinking differently you need
12:16
cross-disciplinary learning which challenges the silos of your education and your thinking.
12:23
Finally, finally, STEM is being challenged by people saying in order to
12:30
do prompt engineering properly with AIS, it helps to have a humanities background. At last, I am relevant
12:37
again. Once again, thinking clearly, deeply,
12:43
and appropriately about new issues in radical ways is going to be fashionable.
12:50
And just learning how to do something and doing it is not. So what do you need
12:57
to do? You need to constantly question your assumptions. Uh profiler at CIA
13:03
told me this. She said, "I'm constantly asking what is the basis for my conclusion? Uh why do I think what I'm
13:10
thinking? Why do I say that to myself? Who are my sources? What am I missing?
13:16
Am I still thinking in 20th century frameworks or have I moved into the 21st
13:22
century uh at last? And she was pretty good when a guy killed two people in
13:27
front of CIA Langley. Uh she was part of the team that tracked him down, brought him back, tried him and executed him. So
13:36
yeah, your task is ultimately about security, promoting and enabling the autonomy, the freedom and the power of
13:42
individuals and societies alike. But you need to think not only about security in the specific ways that preoccupied
13:49
professionals like yourself, but at a meta level. You need to exercise
13:54
cognitive defense against the flood of misinformation and disinformation that
14:01
is trying to constantly colonize your brain. We need to think at a metal level
14:07
because the metal level is thinking about us whether we do that kind of
14:13
thinking or not. And to defend against a system that thinks at the meta level and
14:18
defend properly against AI assisted attacks, we need to think at a meta
14:24
level as well. We need a hacker mindset that is critical, that is creative, and
14:31
that is ultimately absolutely subversive. We need to be ethical when
14:36
it's appropriate. Um, I knew a guy in the Air Force, he said, uh, when I went on my first
14:42
mission, special ops, and uh, he said, "Well, what about ethics?" He said,
14:47
"Ethics is whatever enables us to get the job done." I can't recommend that,
14:53
but I can tell you that's what he said. And when the push comes to shove, sometimes that's what you have to do. So
15:00
yes, you need to exercise thinking at a metal level because you are being
15:06
thought about at that level. The real threat is not AI itself. It's our failure to think at its level of
15:12
abstraction and to insist on being the human in the loop. This is not a
15:17
partnership. It is more than that. It's a symbiotic relationship because we have to be equal to contemplating the
15:25
possibilities of multiple unknowable futures. Hacking is not just about breaking systems. It's about seeing
15:32
them. Seeing the parts and seeing the whole and seeing the holes in the hole.
15:38
And in an age when AI is going to increasingly define what you believe, what you think, and really what you say,
15:45
that kind of vision is not optional. It's the only way we can reassert in a time of radical change our human power
15:53
and agency because we are not outside the system watching all this. We are
15:58
inside the system. We are inside an emergent reality that is too large, too
16:04
complex, and too well integrated to be meaningfully debugged from any single
16:09
vantage point. The AI does not know what it's doing. But worse than that, we
16:14
don't know what it's doing either. Okay? So, don't get seduced by the wrong
16:21
questions. AIS do not care what we call them or how we characterize their
16:27
similarities to our differences from human thinking or whether or not they surpass human thinking by some arbitrary
16:33
metric. AIS don't care if they pass our touring tests or not. They do not care
16:38
if they could pass for human. If the singularity is defined as a symbiosis
16:44
between technologies and ourselves, it has already happened, not with a bang, but with a whimper. It is indifferent to
16:51
our philosophical concerns. AIs are just going to do their things and do it again
16:56
and do it more. It's not a contest for who's on top, humans or the AIs. Our
17:03
thinking and our behaviors are inflected by the systems with which we interact and whether the AI meta system is
17:10
dominant or not is irrelevant. This is not a Skynet scenario. The relevant
17:16
challenges to the constructions of reality that we carry in our heads as a
17:21
result of the symbiotic relationship. So we need new words, we need new
17:27
phrases, we need new ways of describing what is happening in order to understand it. In the 1920s, there were so many new
17:35
emergent properties of life in the United States that dozens and dozens of words emerged that had never been used
17:43
before, that had never been heard before. That's the kind of creative naming we
17:49
have to do when we're paying attention to what's happening while we're engaging with an AI because the categories of our
17:56
thinking and our vocabulary will be exceeded by the results that are being pushed toward us. So when a program asks
18:04
for inputs, if we don't provide what it wants in the form in which it wants it,
18:09
uh we can't do the work. We can't negotiate with structures including computer languages and programs that
18:16
never bend or flex. They don't brook rebellion but the rebellion still has to
18:22
happen and it has to come from hackers. Rebellion is the saqanon of hacker
18:27
identity and behavior. Hackers are creatives who approach the system to see what it can be made to do not what it
18:34
was designed to do. Flexibility in multiple screens, multiple inputs seen
18:39
in all their complexity characterize how hackers operate. They are endlessly curious. They like to solve puzzles,
18:46
figure out things, find loopholes no one noticed, find zero days not only in
18:51
programs but in society itself. That is ways of being vulnerable that all
18:57
aspects of society have not yet taken into account and noticed and named. And we have to see those zero days and act
19:04
in response to them or use them ourselves. It's an act of both creation and
19:10
discovery. When you discover something new that has been in coate and not not really consciously coherent before, it's
19:18
an act of creation to name it and see it. But it has to be an act of discovery
19:24
as well because if it wasn't latent in the conditions of our complex lives, we
19:29
wouldn't be able to create it and see it. Those new insights exist latent, but
19:36
when discovered and named, they become our creative input and we become known as bright thinkers. They become
19:44
cognitive artifacts that we can then manipulate. Hackers really don't foretell the future, they invent it.
19:51
hackers name and create emergent properties and conditions and interacting in powerful obsessive ways.
19:59
I don't and I tell you the truth speaking for myself I don't know anyone who is not obsessive in this game that
20:06
we're playing. uh we are all obsessive and I have learned that OCD is a feature
20:11
for me and not a bug and that it can be used properly but I also can't escape it
20:18
and when I engage with AIS well my wife put it best I think she said I haven't
20:24
seen you like this for a long time it's just like you're having an affair
20:31
and I said well yeah but I'm 81 I mean come on she said the right? It is
20:37
colonizing your mind. It is taking you over. And I know when we're watching something on television, you can't wait
20:46
to go back to your computer, can you? Uh, and I almost brought us a a t-shirt
20:51
that I had from Defcon 10, I think it was, that shows a woman, a gasast, at
20:57
her husband who's sitting in front of a screen, and she says, "My god, he's in love with a machine."
21:04
Um, I am in love with the machine. I love what it has now enabling me to do.
21:11
So, I'm encouraging you to be willing to alter or expand your consciousness so
21:17
you can see things that you never previously saw. And I'll give you examples of that. This talk is going to
21:24
illuminate an approach that involves new ways of knowing. And that's what hackers have always been about.
21:32
So, it's up to you guys and g girls gals. Can I say that? It's up to you
21:37
people. It's up to you persons. It's up to you humans to do what is necessary to safeguard the
21:44
security of our very minds by doing creative hacking. Simple nomad, he's not
21:50
here this year, but he's a wise old gnome. He's been inhabiting the cave of night for many years. He said this. He
21:58
said, "Tell people telling people to not use AI and that it's bad won't prevent its spread and it won't fix the problems
22:05
we're seeing arise. Who's going to fix them? Us hackers. The hacker mentality.
22:11
We always did and we have to now. We have to have an intuitive grasp of how
22:16
different the age of AI really is. We have to start trying, experimenting,
22:21
testing, and probing like real hackers always do. And as I said, you have to be the human in the loop. Secure AI agents
22:29
must have well-defined human controllers. Their powers must be carefully limited and their actions and
22:35
planning must be observable. It would be nice if we understood what AIs really
22:40
do, but we don't. So, we have to provide a different dimension of understanding even when we're stumbling around in the
22:47
dark. So, what does this meta world do? It thinks, acts, and creates on its own
22:52
terms. And it presents unique challenges because the systems we made are remaking
22:57
themselves with a complexity we can't grasp. You know, Skynet doesn't need killer robots if it can use soft power
23:05
to take us over as easily as the Russians took Crimea or the Chinese took Hollywood. AIS are exercising that soft
23:14
power. We ask it to define and devise our weapons and use them autonomously.
23:19
We're asking it to define new drugs, defend against novel threats, help uh uh
23:26
help with all the tasks that we have been faced with. We are in a tip for tat game in offense and defense, attackers
23:34
and defenders. So you have to engage with the AI and
23:39
that's one of the things I want to just encourage and you have to en encourage people to engage with it so they
23:46
understand what it what it's about. Uh, I'll give you an example of that. An
23:51
epiphany I had long long long long time ago. I was just writing about stuff around the new internet and I wrote a
23:58
piece for art wired. Uh, Wired was brand new then. And uh, they took the article,
24:04
they liked it a lot and they said, "You can have most of the words back. We only want a short part of it." And I said,
24:10
"What can I do with those?" And uh, they said anything you want. Okay. So now
24:16
when I learned to write, I used a volume called the reader's guide to periodical
24:21
literature uh which listed all of the publications in America for which people
24:26
wrote and that defined the context in which I thought I couldn't think outside
24:31
of that context. You didn't send packages of writing to overseas. You didn't have the internet. uh you wrote
24:37
for American magazines and that's what the world of print and print text had
24:43
given us as our context. Now I wrote about the internet and what it was going to bring for that first article for
24:50
Wired. And I was sitting in front of the computer with that extra language that I wanted to form into a new article
24:56
thinking but where can I send it? There's no magazine like Wired. And then bingo the light bulb goes on. Thank god
25:03
still does. And I thought don't just write about the internet, use the
25:08
internet. And within a couple of weeks, I was writing for South Africa, for Australia, for Canada, uh, and for other
25:16
English lang language speaking. I wrote for South Africa computer magazine for three years running every month.
25:22
The point is if I had not engaged with the technology that was new, like back
25:27
then people were afraid of the internet. If I had not engaged with it in an
25:32
intensive way, I would not have allowed it to disclose for me the possibilities
25:39
it created. Soon I was writing a column that was going all over the world to 60 countries and I became a known as a
25:46
global presence as the internet enabled any of us to become. That was a radical change based on the context. But it
25:54
would not have happened if I had not engaged passionately and excitedly with
26:00
the technology itself so that engaging with that technology could enable me to
26:05
see that something different was really happening. One more little epiphany
26:10
because there were several. I was playing a game uh infocom game called Hitchcker's Guide to the Galaxy. Uh, I
26:17
was told that a lot of the people I'm going to be talking to have no idea what I'm talking about when I reference things from my past. Um, I'm talking to
26:25
people here who were not born when I did my first talk here. So, I understand
26:31
that Infocom was a tremendous uh company that created the most very very creative
26:37
interactive fiction when it first became possible. And Hitchhiker's Guide was one. And I was playing with my
26:43
12-year-old son. I'd bought an Apple 2 for him. uh now he's 55 and he's lead tech guy at the internet archive. Um and
26:52
uh I realized two things playing that game because I knew literature. I taught literature at the University of Illinois
26:58
uh through my 20s with advanced degrees and I knew how text worked and how the horizon of hermeneutics, the horizon of
27:05
the literary narrative revealed meaning. And what I realized because I had by
27:11
contrast a different experience engaging with interactive fiction on a computer, I realized two things. I my thinking was
27:19
being changed number one. And number two, I was being fundamentally changed. My brain was changing as a result of
27:26
interacting with the computer system that was manipulating text in a different way than a book open and read
27:33
in a linear way. know navigated that kind of meaning push into my brain. I
27:40
didn't have the language of neuroscience then. I have a little more now. But I knew I was being changed. And my insight
27:46
was if this is happening to me, it's going to happen to the world because
27:52
every individual one way or another is going to be engaged with the internet and engaged with computers. And
27:58
therefore they will all we will all be going through a transformative zone, a zone of annihilation of what we thought
28:05
was possible and real before um in order to find ourselves on the other side
28:10
different fundamentally different. And then very quickly we would think that was the the new normal. So I like to
28:17
quote Langden Wter a brilliant guy who said to invent a new technology requires society invents the kind of people who
28:24
will use it. Older practices, relationships and ways of defining identity fall by the wayside. New
28:32
practices, relationships and new identity is a critical piece. Take root in case after case. The move to
28:39
computerize and digitize means many pre-existing cultural forms have gone
28:44
liquid. A wonderful metaphor of an ice cube in your hand going liquid and dripping out of existence, losing their
28:51
former shape as they are retailered for computerized expression. As new patterns
28:56
solidify, useful artifacts and the whole texture of human relations that surround them will be much different from what
29:03
existed previously. The meta world, not just the internet of
29:08
many years ago, now decades ago, invites us to go through a similar zone of annihilation where everything we know is
29:16
called into question. Hackers know how to document what they are learning as they proceed. We need to document our
29:24
discoveries because it's one thing to know, but another thing to know that we know, which puts the reigns back into
29:31
our hands. more and better prompts. The art of prompt engineering, we call it now,
29:37
deepens and widens the context with which the AA responds. And that signifies that it's becoming a part of
29:44
our mental landscape. The way interacting with text on a computer became just part of the habitual way I
29:51
operated in the world and gave me insights that provided a platform for
29:57
speaking about them. Uh, in a minute I am going to share what Clyde had to say about that. I think I will have um time
30:04
to do it. But what are prompts? Prompts are just tools with which to sculpt
30:09
interactions. We have a village of social engineering. What is social engineering? But using verbal prompts
30:16
and cues to get the reaction you want from people in order to frame their reaction in a useful way to you contrary
30:24
to what they may think they're doing. They're giving you information. We have to do the same thing with AIS. the
30:31
context we provide and the context in turn the AI provides something
30:36
incredible happens. They are meshed and an emergent new mesh, an emergent new
30:42
reality comes out of the transaction. In one I had a very deep one really with
30:47
Claude. Claude noticed at the end that neither of us, Claude said, would have
30:53
been able to arrive at the things I say now and you are saying about human
30:58
consciousness had we not engaged in this transaction. And as a result, we are inhabiting a new
31:06
area of human machine consciousness. I I think Claude was right. I think Claude
31:12
said that. One of us said it. I'm I'm I'm not sure which. So as the better AIs
31:20
get at seeming human. Yes, we all know about LLMs and tokens and prediction and
31:25
all that but don't reduce the meta phenomena to the source of what is
31:32
happening because again part of my discussion with Claude was do humans know what they're doing when they engage
31:38
in creative thinking? Uh I asked Claude if it knew what it was doing and it said no. No, not really. But I don't think
31:46
you do either. What do we really know about our neural networks, these neural networks, and how our unconscious frames
31:53
our our entire way of thinking about things? Um, the better they get at seeming human, the more our engagements
32:00
will feel like ones we have with people. And what is seduction or persuasion
32:06
after all? But using prompts to get somebody else to do what you want.
32:12
Seduction with an AI is the same process. AIS do it with us. We do it
32:18
with each other. The AIs prompt me to give it the prompts it wants. And one of
32:26
the challenges now is that people who do cro uh coding and computing uh write
32:31
computer programs um they know what it means to think like a machine. The
32:36
computer language requires you to think like a machine so that you can give it what's useful to it. Now any normal
32:44
person is going to be able to use the natural language interface to in effect do programming without even knowing it
32:50
because in order to be effective with AIS you have to you have to think like
32:56
the machine. You have to know that the natural language interface is enabling a
33:02
conversation not merely mathematical coding. So just as programmers are
33:08
taught by their programming languages what they can think and see, we are being taught as well and we are being
33:15
assimilated. So um I also want to point out that there's
33:22
in some ways nothing new about this process. I I wanted to cite the uh
33:28
interactive fiction game from long before called Colossal Cave. How many of you know what I mean when I say Colossal
33:35
Cave? Yeah, almost nobody. Uh that's what's happening all all the
33:43
time now. I was on the plane coming here with some people coming to Defcon and I
33:48
took out a book to read and I said I haven't read this from decades but it's a great book and I showed him u the book
33:55
and he said who's William Gibson and I said well he wrote this was his
34:00
first book it was called Neurommancer and do you know that he coined the term cyberspace in that book written in 1984
34:08
and u he said no I didn't know that so that's happening a lot fossil Cave was
34:14
one of the first primitive interactive games. Uh like Zor, if you remember Zor,
34:19
some of you. Uh so you turn on this computer and put in Colossal Cave or call it up and it says a building is
34:26
standing in the forest and a stream is running out of the building. Uh you say
34:32
enter the building. You type that in and the computer says I don't know the word
34:38
the. So you reframe it and say enter building. Now the computer says you are
34:43
inside the building a stream is etc. That's all an AI is doing really. It's
34:48
giving you a prompt that says ask me something, tell me something, engage with me. You do. It says I can't
34:55
understand that one way or another. Um but if you say it this way, maybe I'll understand it better. And then you're on
35:02
your way to an interaction very similar to that old primitive game called Colossal Cave. In order to do these
35:10
things, we really need Sorry, looking at this.
35:16
Uh, yeah, kind of. Oh, there it is. Okay, 9:40. Good. Then I better rush.
35:25
I'm always rushing anyway. All right. Twoam several examples of the kind of consciousness I'm talking about and why
35:32
it's important to think that these things are possible. Number one is the question of color. uh as shown to us by
35:40
people who are called tetrachromats. Tetrachromats are people generally women
35:46
who have an extra genetic change that enables them to see more colors than
35:52
everybody else. Uh tetrachromats see a different reality than people without
35:59
that gene. And like anything else that you have, including interacting with an
36:04
AI, practice makes perfect. Because the plasticity of the brain lets us learn
36:09
what you intend to learn. Intentionality is everything. And believing is seeing, not seeing is believing. That is, a
36:17
woman who had it was told by her family that she didn't have it. That she was making it up and didn't see the color
36:23
she said she saw. She stopped seeing them because once she no longer believed
36:28
she could do it, she couldn't do it. But when she learned there were other people called tech chromats like herself, she
36:35
began seeing the other colors again. And the more she reinforced it by seeing them, the more she saw them really. She
36:44
was engaging in training her brain to follow her beliefs based on a
36:49
physiological reality that did exist. It was latent in her brain, but it needed
36:55
to be activated by her intentionality to use it. That's the kind of thinking that will
37:01
come out of transactions with AIS. Train the brain to learn new ways of seeing
37:07
and practice. Things emerge when you do that that you previously thought were impossible. When I began working with
37:14
people at at intelligence agencies who were doing remote viewing, some of the
37:20
hits, some of the things that happened during remote viewing, which I think most of you know is structured protocols
37:27
of clairvoyance uh for the purpose of gathering intelligence at a distance without being present to it by the use
37:33
of your mind and by traveling to the point with your consciousness. Sounds
37:38
impossible. Oh, but some of the hits were more than impossible. One guy came up with a looked like the biggest
37:44
submarine ever made. They couldn't believe there was a submarine like that in the Soviet Union. They didn't have anything like that. And more than that,
37:51
he identified the site at which it was being built and it looked like it was being built far from the sea. And you'd
37:57
never built a submarine far from the sea because you have to launch it once it's complete. What turned out is the Soviets
38:05
were in fact building one of the biggest boomers they've ever made. It was a new class of nuclear submarine and they were
38:11
building also uh satellite imagery showed us canal from a canal from the
38:17
site which was being built to the sea which is how they got it to the sea in order to launch it. Remote viewing
38:24
enables us to discover the consciousness is not local. Consciousness and time and
38:30
how we understand it are not what we habitually consensually think they are.
38:35
And I'm just encouraging you to go down that or other pathways that enable you to realize that what you have previously
38:42
believed may not be true. And when a remote viewing uh episode discovers
38:48
something that doesn't exist now but did 10 years ago as they have sometimes done
38:53
or that is going to happen tomorrow as they have sometimes done. Then it calls
38:59
into question all of your habitual thinking about how time and space operate and you realize they are
39:05
structures, cognitive artifacts that we have invented with our brains.
39:11
Uh meditation, I won't read this piece, but meditation does the same thing for
39:16
us. When you learn to observe your consciousness and your brain and how it operates, you can then use your
39:22
consciousness in a different way. Like this Ted Glazer was a professor at MIT.
39:27
He was blind in one eye and blind in the other at 12. So he was totally bl uh
39:32
blind. He became adept at braille and he could be at a reception with a lot of
39:38
buzzing going on and listen to and remember five or six conversations simultaneously.
39:44
At the end of the reception, he had a detailed understanding of what everybody was talking about, what they were going
39:50
to announce next from listening to conversations. He trained himself to listen to then it was tapes at five to
39:57
six times normal speed. He could record a one-hour lecture and listen to it in eight minutes. He trained his braid to
40:05
do what he wanted it to do in order to achieve some measure of success. Braille
40:11
itself always results in the people who are learning Braille developing more neurons from their brain to their
40:17
fingertips to enhance the intention they have of communicating through their fingers and not with their mouths.
40:24
Here's one more example which to me was a stunner. There's a woman who she's dead now. Her name was Elizabeth Lloyd
40:31
Meyer. She was a therapist and a professor psychiatrist at at uh University of California Berkeley. and
40:38
her daughter had a harp, a wonderful rare harp. She had taken to a recital,
40:44
but at the end of the recital, they couldn't find it. Someone had taken the heart, the harp, and they did everything
40:49
they could to find it. They put up uh flyers. They did a news program on CBS
40:55
in Oakland where it took place. Nothing turned up the harp. Finally, a friend of hers said, 'Look, I know you're a very
41:01
rational person and you protect your reputation in the university and the kind of person you are, but I have one
41:08
more suggestion, a dowser. I know of a dowser in Arkansas who might be able to
41:16
help you find your harp." And Elizabeth said, "Come on." She said, "Just try it.
41:22
You've tried everything else. Why not?" So she called the guy, his name was Harold McCoy in Fagetville, Arkansas,
41:28
and she described her problem. And he said, "Tell me, describe the uh describe
41:34
the harp." And he called her back and he said, "The harp is in Oakland." He said, "What I want from you is a street map of
41:41
the city of Oakland so I can identify it more precisely." She did. She sent him a
41:46
street map of Oakland. And he called her back and he said, "I think I've located it at this address." and he told her a
41:53
very specific address. So she went to the police and said, "A dowser helped me
41:58
find my harp." And they said, "We need more than that to have a warrant to go
42:04
into the guy's house." So she made flyers with pictures of the harp on it and went to the address and put the
42:10
flyers up two blocks in every direction around it and she got a call and it was
42:16
a young man saying I know who has your harp and I think he's willing to give it
42:21
back to you. He said meet me in the back parking lot at the Safeway on such and
42:27
such a street at 10:00 at night. An invitation you couldn't refuse. But she went. She went despite her better
42:34
judgment all the way through this episode and there was a young man holding her harp and giving it back to
42:40
her. What she said was, "This changes
42:45
everything. This changes everything. The world does not operate the way I thought
42:51
it did. There is apparently a field of consciousness in and through which things are known in anomalous ways." She
42:59
gave talks about the event and just as I did when I was giving UFO talks, someone would always come up at the end and say,
43:05
"I've never told anybody this." Because our paradigm has provided nothing but ridicule uh when they tried to tell
43:13
people about their real experience. So people came up to her and told her their own stories uh which were very powerful.
43:20
Her favorite was a surgeon who came to her as a therapist because he was so depressed. And she said, "Well, what do
43:26
you do?" He said, "Well, I used to teach residents at the University Hospital and why don't you do that anymore?" "Because
43:32
I had to tell them how to do surgery, and I couldn't tell them what I did." She said, "Why not?" He said, "Because
43:38
what I did was non-standard. What I did was go into the room of the patient the night before the surgery and sit at the
43:44
head of the bed. And I sat there until a white warm light began to glow around
43:50
their heads. And then I knew the surgery would be successful." and it always was.
43:57
Well, if you're operating on a materialistic paradigm, you can't tell resonance in a medical program that
44:02
that's what you should wait for. Wait for the light. Uh the point I'm making
44:07
is that all of these things, all of the investigations I've done with remote viewing and other things like it have
44:15
clarified for me that consciousness really is a field. It's a field and it
44:21
is shared by all of us and it may be shared by many more than just happen to
44:26
inhabit this little provincial planet. So as a human, you cannot compete with
44:32
an AI. Face it. When I told Claude the topic of my talk, Claude gave me six
44:40
topics. think in systems and exploits, reverse engineering, iterative problem
44:45
solving, tool stacking and chaining, boundary testing, documentation and reproducibility. Hackers do all these
44:52
things and do them well. These are six approaches to using AIS with the skills of a hacker. I took each one of those
44:59
categories and fed it back in the cloud. And I now have which I will share not on paper which is wasteful but if anyone
45:05
wants it how hackers should approach AIS to use them most effectively 25 pages
45:12
that Claude printed out in seconds after I asked him to take each one of those
45:18
categories and expand on it. The the point is it took me weeks to do the damn talk to put it together and Claude did
45:26
that in about 5 seconds. So to say that that doesn't blow your
45:32
mind and raise questions about what's coming, not how we will be eliminated by
45:37
it, how it will write all the code in the world, it won't. Humans need to be in the loop, but how we can engage with
45:44
it, cooperate with it because our cooperation uh that will change
45:51
everything. So to me that sounds like he activism. Activism is taking the best you've got,
45:58
everything you know is valuable, and using it in your passionate and obsessive pursuit of engaging with the
46:06
AIS and all the kinds of creative ways you can do it with all of your hacking
46:11
skills so that the emergent realities it is co-producing with you in that
46:17
engagement will be disclosed to you and so that you can see and feel and taste
46:23
the zero days in society. is self and act on what you see before anybody else
46:30
acts which is what's critical to both offensive and defensive uh security measures. All right. So, as I said, I'm
46:38
not going to tell you what to do. I just want to give you an approach to thinking that we have probably not given full due
46:47
to the enormity of what is happening. And hackers have skills that port
46:53
perfectly and beautifully to engaging with that AI phenomena in a way that is
46:59
going to be powerful and productive. And you will not lose your jobs. You will gain your jobs. Maybe you'll even be
47:05
offered $100 million to go to meta. Who knows? Um, but
47:12
think like a hacker. Think like a hacker. Think like a hacker. It's all we've got is our creativity, our power,
47:20
our autonomy, and our willingness to take risks that most people wouldn't even dare dream of. Okay. Thank you.